"""JsLex: a lexer for Javascript"""
#ANNOTATION: docstring
# Originally from https://bitbucket.org/ned/jslex
import re
#ANNOTATION: import module re.


class Tok(object):
#ANNOTATION: derive the class Tok from the object base class.
    """
    A specification for a token class.
    """
#ANNOTATION: docstring
    num = 0
#ANNOTATION: num is an integer 0.

    def __init__(self, name, regex, next=None):
#ANNOTATION: define the method __init__ with 4 arguments: self, name, regex and next set to None.
        self.id = Tok.num
#ANNOTATION: substitute Tok.num for self.id.
        Tok.num += 1
#ANNOTATION: increment Tok.num with an integer 1.
        self.name = name
#ANNOTATION: substitute name for self.name.
        self.regex = regex
#ANNOTATION: substitute regex for self.regex.
        self.next = next
#ANNOTATION: substitute next for self.next.


def literals(choices, prefix="", suffix=""):
#ANNOTATION: define the function literals with 3 arguments: choices, prefix set to an empty string and suffix set to an empty string.
    """
    Create a regex from a space-separated list of literal `choices`.

    If provided, `prefix` and `suffix` will be attached to each choice
    individually.

    """
#ANNOTATION: docstring
    return "|".join(prefix + re.escape(c) + suffix for c in choices.split())
#ANNOTATION: for every c in choices split into words, concatenate prefix, result of the function re.escape with an argument c and suffix,
#ANNOTATION: and join the results into a string, separated with '|' character, return the result.


class Lexer(object):
#ANNOTATION: derive the class Lexer from the object base class.
    """
    A generic multi-state regex-based lexer.
    """
#ANNOTATION: docstring

    def __init__(self, states, first):
#ANNOTATION: define the method __init__ with 3 arguments self, states and first.
        self.regexes = {}
#ANNOTATION: self.regexes is an empty dictionary.
        self.toks = {}
#ANNOTATION: self.tokens is an empty dictionary.

        for state, rules in states.items():
#ANNOTATION: call the method states.items, for every state and rules in the result,
            parts = []
#ANNOTATION: parts is an empty list.
            for tok in rules:
#ANNOTATION: for every tok in rules,
                groupid = "t%d" % tok.id
#ANNOTATION: groupid is a string "t%d" formated with tok.id.
                self.toks[groupid] = tok
#ANNOTATION: substitute tok for value under the groupid key of the self.toks dictionary.
                parts.append("(?P<%s>%s)" % (groupid, tok.regex))
#ANNOTATION: format a string "(?P<%s>%s)" with groupid and tok.regex, append it to the parts.
            self.regexes[state] = re.compile("|".join(parts), re.MULTILINE | re.VERBOSE)
#ANNOTATION: call the function re.compile with 2 arguments: elements of parts joined into a string, separated with '|',
#ANNOTATION: and result of bitwise OR performed on 2 operands: re.MULTILINE and re.VERBOSE, 
#ANNOTATION: substitute the result for value under the state key of the self.regexes dictionary.

        self.state = first
#ANNOTATION: substitute first for self.state.

    def lex(self, text):
#ANNOTATION: define the method lex with 2 arguments self and text.
        """
        Lexically analyze `text`.

        Yields pairs (`name`, `tokentext`).
        """
#ANNOTATION: docstring
        end = len(text)
#ANNOTATION: substitute length of text for end.
        state = self.state
#ANNOTATION: substitute self.state for state.
        regexes = self.regexes
#ANNOTATION: substitute self.regexes for regexes.
        toks = self.toks
#ANNOTATION: substitute self.toks for toks.
        start = 0
#ANNOTATION: start is an integer 0.

        while start < end:
#ANNOTATION: while start is lesser than end.
            for match in regexes[state].finditer(text, start):
#ANNOTATION: get the value under the state key of the regexes dictionary, call the method finditer on the result with 2 arguments: text and start,
#ANNOTATION: for every match in the result,
                name = match.lastgroup
#ANNOTATION: substitute match.lastgroup for name.
                tok = toks[name]
#ANNOTATION: substitute value under the name key of the toks dictionary for tok.
                toktext = match.group(name)
#ANNOTATION: call the method match.group with an arugument name, substitute the result for toktext.
                start += len(toktext)
#ANNOTATION: increment start by length of toktext.
                yield (tok.name, toktext)
#ANNOTATION: yield a tuple with 2 elements: tok.name and toktext.

                if tok.next:
#ANNOTATION: if tok.next is true,
                    state = tok.next
#ANNOTATION: substitute tok.next for state.
                    break
#ANNOTATION: break from the loop execution.

        self.state = state
#ANNOTATION: substitute state for self.state.


class JsLexer(Lexer):
#ANNOTATION: derive the class JsLexer from the Lexer base class.
    """
    A Javascript lexer

    >>> lexer = JsLexer()
    >>> list(lexer.lex("a = 1"))
    [('id', 'a'), ('ws', ' '), ('punct', '='), ('ws', ' '), ('dnum', '1')]

    This doesn't properly handle non-ASCII characters in the Javascript source.
    """
#ANNOTATION: docstring

    # Because these tokens are matched as alternatives in a regex, longer
    # possibilities must appear in the list before shorter ones, for example,
    # '>>' before '>'.
    #
    # Note that we don't have to detect malformed Javascript, only properly
    # lex correct Javascript, so much of this is simplified.

    # Details of Javascript lexical structure are taken from
    # http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-262.pdf

    # A useful explanation of automatic semicolon insertion is at
    # http://inimino.org/~inimino/blog/javascript_semicolons

    both_before = [
        Tok("comment", r"/\*(.|\n)*?\*/"),
        Tok("linecomment", r"//.*?$"),
        Tok("ws", r"\s+"),
        Tok("keyword", literals("""
                           break case catch class const continue debugger
                           default delete do else enum export extends
                           finally for function if import in instanceof
                           new return super switch this throw try typeof
                           var void while with
                           """, suffix=r"\b"), next='reg'),
        Tok("reserved", literals("null true false", suffix=r"\b"), next='div'),
        Tok("id", r"""
                  ([a-zA-Z_$   ]|\\u[0-9a-fA-Z]{4})   # first char
                  ([a-zA-Z_$0-9]|\\u[0-9a-fA-F]{4})*  # rest chars
                  """, next='div'),
        Tok("hnum", r"0[xX][0-9a-fA-F]+", next='div'),
        Tok("onum", r"0[0-7]+"),
        Tok("dnum", r"""
                    (   (0|[1-9][0-9]*)     # DecimalIntegerLiteral
                        \.                  # dot
                        [0-9]*              # DecimalDigits-opt
                        ([eE][-+]?[0-9]+)?  # ExponentPart-opt
                    |
                        \.                  # dot
                        [0-9]+              # DecimalDigits
                        ([eE][-+]?[0-9]+)?  # ExponentPart-opt
                    |
                        (0|[1-9][0-9]*)     # DecimalIntegerLiteral
                        ([eE][-+]?[0-9]+)?  # ExponentPart-opt
                    )
                    """, next='div'),
        Tok("punct", literals("""
                         >>>= === !== >>> <<= >>= <= >= == != << >> &&
                         || += -= *= %= &= |= ^=
                         """), next="reg"),
        Tok("punct", literals("++ -- ) ]"), next='div'),
        Tok("punct", literals("{ } ( [ . ; , < > + - * % & | ^ ! ~ ? : ="), next='reg'),
        Tok("string", r'"([^"\\]|(\\(.|\n)))*?"', next='div'),
        Tok("string", r"'([^'\\]|(\\(.|\n)))*?'", next='div'),
    ]
#ANNOTATION: both_before is a list containing 14 elements, all of them are instances of Tok class, created with 2 arguments, a string and a raw string.

    both_after = [
        Tok("other", r"."),
    ]
#ANNOTATION: both_after is an list with an element instance of Tok class, created with 2 arguments: string 'other' and raw string '.'.

    states = {
        # slash will mean division
        'div': both_before + [
            Tok("punct", literals("/= /"), next='reg'),
        ] + both_after,

        # slash will mean regex
        'reg': both_before + [
            Tok("regex",
                r"""
                    /                       # opening slash
                    # First character is..
                    (   [^*\\/[]            # anything but * \ / or [
                    |   \\.                 # or an escape sequence
                    |   \[                  # or a class, which has
                            (   [^\]\\]     #   anything but \ or ]
                            |   \\.         #   or an escape sequence
                            )*              #   many times
                        \]
                    )
                    # Following characters are same, except for excluding a star
                    (   [^\\/[]             # anything but \ / or [
                    |   \\.                 # or an escape sequence
                    |   \[                  # or a class, which has
                            (   [^\]\\]     #   anything but \ or ]
                            |   \\.         #   or an escape sequence
                            )*              #   many times
                        \]
                    )*                      # many times
                    /                       # closing slash
                    [a-zA-Z0-9]*            # trailing flags
                """, next='div'),
        ] + both_after,
    }
#ANNOTATION: states is a dictionary with 2 arguments: appended list with an element instance of a class Tok, created with 3 arguments: "punct",
#ANNOTATION: result of the function literals called with an argument string "/= /" and next as a string 'reg', to the both_before,
#ANNOTATION: appended both_after to the previous result, for 'div' and appended list with an element instance of a class Tok, 
#ANNOTATION: created with 3 arguments: string "regex", 
#ANNOTATION: raw string '/([^*\\/[]|\\.|\[(   [^\]\\]|   \\.)*\])(   [^\\/[]|   \\.|   \[(   [^\]\\]|   \\.)*\])*/[a-zA-Z0-9]*',
#ANNOTATION: and next as a string 'div', to the both_before, appended both_after to the previous result for 'div'.

    def __init__(self):
#ANNOTATION: define the method __init__ with an argument self.
        super(JsLexer, self).__init__(self.states, 'reg')
#ANNOTATION: call the method __init__ with 2 arguments: self.states and string 'reg' from the base class of the class JsLexer.


def prepare_js_for_gettext(js):
#ANNOTATION: define the function prepare_js_for_gettext with an argument js.
    """
    Convert the Javascript source `js` into something resembling C for
    xgettext.

    What actually happens is that all the regex literals are replaced with
    "REGEX".
    """
#ANNOTATION: docstring
    def escape_quotes(m):
#ANNOTATION: define the function escape_quotes with an argument m.
        """Used in a regex to properly escape double quotes."""
#ANNOTATION: docstring
        s = m.group(0)
#ANNOTATION: call the method m.group with an argument integer 0, substitute the result for s.
        if s == '"':
#ANNOTATION: if s equals a string '"',
            return r'\"'
#ANNOTATION: return an raw string '\"'.
        else:
#ANNOTATION: if not,
            return s
#ANNOTATION: return s.

    lexer = JsLexer()
#ANNOTATION: lexer is an instance of JsLexer class.
    c = []
#ANNOTATION: c is an empty list.
    for name, tok in lexer.lex(js):
#ANNOTATION: call the method lexer.lex with an arguments js, for every name and tok in the result,
        if name == 'regex':
#ANNOTATION: if name equals a string 'regex',
            # C doesn't grok regexes, and they aren't needed for gettext,
            # so just output a string instead.
            tok = '"REGEX"'
#ANNOTATION: tok is a string '"REGEX"',
        elif name == 'string':
#ANNOTATION: otherwise if name starts with a string 'string',
            # C doesn't have single-quoted strings, so make all strings
            # double-quoted.
            if tok.startswith("'"):
#ANNOTATION: if tok starts with "'",
                guts = re.sub(r"\\.|.", escape_quotes, tok[1:-1])
#ANNOTATION: call the function re.sub with 3 arguments: raw string "\\.|.", escape_quotes and tok without the first and last element, 
#ANNOTATION: substitute the result for guts. 
                tok = '"' + guts + '"'
#ANNOTATION: concatenate string '"', guts and string '"', substitute the result for tok.
        elif name == 'id':
#ANNOTATION: otherwise if name equals a string 'id'.
            # C can't deal with Unicode escapes in identifiers.  We don't
            # need them for gettext anyway, so replace them with something
            # innocuous
            tok = tok.replace("\\", "U")
#ANNOTATION: replace every occurrence of '\\' in tok with 'U', substitute the result for tok.
        c.append(tok)
#ANNOTATION: append tok to c.
    return ''.join(c)
#ANNOTATION: join elements of c into a string, return it.
